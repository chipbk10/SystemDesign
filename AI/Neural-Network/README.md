- Output = **Activation-Function** ( **Sum-Up**[ weight * input ] )
- The analogy is like

*   **Inputs = Ingredients**  
    Each input feature is like an ingredient you have available.

*   **Weights = How much of each ingredient you add**  
    The network learns the right proportions (weights) during training.

*   **Sum = Mixing them into one dish**  
    Combine all weighted ingredients into a single mixture (the neuron’s combined signal).

*   **Activation = Tasting and deciding if it’s good enough to serve**  
    The activation function decides whether this combined signal is strong enough to pass forward.

*   **Trained model = The recipe**  
    After training, you have a recipe that tells you exactly how much of each ingredient to use.

*   **Inference = Cooking using the recipe**  
    When new inputs come in, you follow the recipe (weights) and serve the dish (output) without experimenting anymore.
